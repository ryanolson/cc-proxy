default_mode = "anthropic-only"

[server]
listen_address = "0.0.0.0:3080"

[primary]
upstream_base_url = "https://api.anthropic.com"
passthrough_auth = true
timeout_secs = 300

[shadow]
litellm_url = "http://litellm-service:4000/v1/chat/completions"
litellm_api_key = ""
models = ["gemini-2.5-flash", "deepseek-v3.2", "glm-5", "gemini-3-pro"]
timeout_secs = 120
max_concurrent = 50


[tracing]
service_name = "shadow-proxy"
log_level = "info"
